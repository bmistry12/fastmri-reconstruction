----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [1, 8, 320, 320]              16
    InstanceNorm2d-2           [1, 8, 320, 320]               0
              ReLU-3           [1, 8, 320, 320]               0
         Dropout2d-4           [1, 8, 320, 320]               0
            Conv2d-5           [1, 8, 320, 320]              72
    InstanceNorm2d-6           [1, 8, 320, 320]               0
              ReLU-7           [1, 8, 320, 320]               0
         Dropout2d-8           [1, 8, 320, 320]               0
         ConvBlock-9           [1, 8, 320, 320]               0
           Conv2d-10          [1, 16, 160, 160]             144
   InstanceNorm2d-11          [1, 16, 160, 160]               0
             ReLU-12          [1, 16, 160, 160]               0
        Dropout2d-13          [1, 16, 160, 160]               0
           Conv2d-14          [1, 16, 160, 160]             272
   InstanceNorm2d-15          [1, 16, 160, 160]               0
             ReLU-16          [1, 16, 160, 160]               0
        Dropout2d-17          [1, 16, 160, 160]               0
        ConvBlock-18          [1, 16, 160, 160]               0
           Conv2d-19            [1, 32, 80, 80]             544
   InstanceNorm2d-20            [1, 32, 80, 80]               0
             ReLU-21            [1, 32, 80, 80]               0
        Dropout2d-22            [1, 32, 80, 80]               0
           Conv2d-23            [1, 32, 80, 80]           1,056
   InstanceNorm2d-24            [1, 32, 80, 80]               0
             ReLU-25            [1, 32, 80, 80]               0
        Dropout2d-26            [1, 32, 80, 80]               0
        ConvBlock-27            [1, 32, 80, 80]               0
           Conv2d-28            [1, 64, 40, 40]           2,112
   InstanceNorm2d-29            [1, 64, 40, 40]               0
             ReLU-30            [1, 64, 40, 40]               0
        Dropout2d-31            [1, 64, 40, 40]               0
           Conv2d-32            [1, 64, 40, 40]           4,160
   InstanceNorm2d-33            [1, 64, 40, 40]               0
             ReLU-34            [1, 64, 40, 40]               0
        Dropout2d-35            [1, 64, 40, 40]               0
        ConvBlock-36            [1, 64, 40, 40]               0
           Conv2d-37            [1, 64, 20, 20]           4,160
   InstanceNorm2d-38            [1, 64, 20, 20]               0
             ReLU-39            [1, 64, 20, 20]               0
        Dropout2d-40            [1, 64, 20, 20]               0
           Conv2d-41            [1, 64, 20, 20]           4,160
   InstanceNorm2d-42            [1, 64, 20, 20]               0
             ReLU-43            [1, 64, 20, 20]               0
        Dropout2d-44            [1, 64, 20, 20]               0
        ConvBlock-45            [1, 64, 20, 20]               0
           Conv2d-46            [1, 32, 40, 40]           4,128
   InstanceNorm2d-47            [1, 32, 40, 40]               0
             ReLU-48            [1, 32, 40, 40]               0
        Dropout2d-49            [1, 32, 40, 40]               0
           Conv2d-50            [1, 32, 40, 40]           1,056
   InstanceNorm2d-51            [1, 32, 40, 40]               0
             ReLU-52            [1, 32, 40, 40]               0
        Dropout2d-53            [1, 32, 40, 40]               0
        ConvBlock-54            [1, 32, 40, 40]               0
           Conv2d-55            [1, 16, 80, 80]           1,040
   InstanceNorm2d-56            [1, 16, 80, 80]               0
             ReLU-57            [1, 16, 80, 80]               0
        Dropout2d-58            [1, 16, 80, 80]               0
           Conv2d-59            [1, 16, 80, 80]             272
   InstanceNorm2d-60            [1, 16, 80, 80]               0
             ReLU-61            [1, 16, 80, 80]               0
        Dropout2d-62            [1, 16, 80, 80]               0
        ConvBlock-63            [1, 16, 80, 80]               0
           Conv2d-64           [1, 8, 160, 160]             264
   InstanceNorm2d-65           [1, 8, 160, 160]               0
             ReLU-66           [1, 8, 160, 160]               0
        Dropout2d-67           [1, 8, 160, 160]               0
           Conv2d-68           [1, 8, 160, 160]              72
   InstanceNorm2d-69           [1, 8, 160, 160]               0
             ReLU-70           [1, 8, 160, 160]               0
        Dropout2d-71           [1, 8, 160, 160]               0
        ConvBlock-72           [1, 8, 160, 160]               0
           Conv2d-73           [1, 8, 320, 320]             136
   InstanceNorm2d-74           [1, 8, 320, 320]               0
             ReLU-75           [1, 8, 320, 320]               0
        Dropout2d-76           [1, 8, 320, 320]               0
           Conv2d-77           [1, 8, 320, 320]              72
   InstanceNorm2d-78           [1, 8, 320, 320]               0
             ReLU-79           [1, 8, 320, 320]               0
        Dropout2d-80           [1, 8, 320, 320]               0
        ConvBlock-81           [1, 8, 320, 320]               0
           Conv2d-82           [1, 4, 320, 320]              36
           Conv2d-83           [1, 1, 320, 320]               5
           Conv2d-84           [1, 1, 320, 320]               2
================================================================
Total params: 23,779
Trainable params: 23,779
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.39
Forward/backward pass size (MB): 192.77
Params size (MB): 0.09
Estimated Total Size (MB): 193.25
----------------------------------------------------------------
Training on 1714
Validating on 420
Epoch: 1/20
 Train Loss: 0.1311155143395596 | Validation Loss: 0.12986062226332812
Train Time: 42.62154281898984 | Validation Time: 10.717929034988629
Epoch: 2/20
 Train Loss: 0.1209616912551524 | Validation Loss: 0.13108630059098797
Train Time: 42.842697688989574 | Validation Time: 10.798115584999323
Epoch: 3/20
 Train Loss: 0.12994268980973867 | Validation Loss: 0.12440478607779643
Train Time: 42.943512349011144 | Validation Time: 10.84398107000743
Epoch: 4/20
 Train Loss: 0.12111248963352063 | Validation Loss: 0.1216923930642418
Train Time: 42.998293871991336 | Validation Time: 10.852542839973466
Epoch: 5/20
 Train Loss: 0.12464976485017859 | Validation Loss: 0.1279268313220531
Train Time: 42.984166840004036 | Validation Time: 10.842907276004553
Epoch: 6/20
 Train Loss: 0.12593365440034554 | Validation Loss: 0.13437987496749212
Train Time: 42.90572981900186 | Validation Time: 10.854422146978322
Epoch: 7/20
 Train Loss: 0.12039142424355392 | Validation Loss: 0.11721475078410894
Train Time: 43.00043819300481 | Validation Time: 10.821260007011006
Epoch: 8/20
 Train Loss: 0.11928485231888092 | Validation Loss: 0.11774537332467402
Train Time: 43.02550187599263 | Validation Time: 10.812636432005093
Epoch: 9/20
 Train Loss: 0.11234717310371337 | Validation Loss: 0.12030686425397781
Train Time: 42.960265475005144 | Validation Time: 10.86499581701355
Epoch: 10/20
 Train Loss: 0.1139874846454212 | Validation Loss: 0.1270234789889479
Train Time: 43.00653219001833 | Validation Time: 10.839683981001144
Epoch: 11/20
 Train Loss: 0.11551743437177771 | Validation Loss: 0.11751780343876585
Train Time: 42.97658099900582 | Validation Time: 10.802461340994341
Epoch: 12/20
 Train Loss: 0.12369068790150305 | Validation Loss: 0.12048734944313597
Train Time: 43.03246245798073 | Validation Time: 10.865153427992482
Epoch: 13/20
 Train Loss: 0.12214155068058251 | Validation Loss: 0.11945885386894002
Train Time: 43.00305462599499 | Validation Time: 10.841719841002487
Epoch: 14/20
 Train Loss: 0.110008979067074 | Validation Loss: 0.11846707393475019
Train Time: 43.030169495992595 | Validation Time: 10.825944119977066
Epoch: 15/20
 Train Loss: 0.11717747582065809 | Validation Loss: 0.11523242212595196
Train Time: 43.044663028995274 | Validation Time: 10.826743179000914
Epoch: 16/20
 Train Loss: 0.11712039327426427 | Validation Loss: 0.11047110597597348
Train Time: 43.01250437699491 | Validation Time: 10.853387132985517
Epoch: 17/20
 Train Loss: 0.11698010922365512 | Validation Loss: 0.11307917705315758
Train Time: 43.03604939900106 | Validation Time: 10.847407969995402
Epoch: 18/20
 Train Loss: 0.1163626961286756 | Validation Loss: 0.12006097339726925
Train Time: 43.005540131009184 | Validation Time: 10.854557956015924
Epoch: 19/20
 Train Loss: 0.12465882399879501 | Validation Loss: 0.11137903341085487
Train Time: 43.002147341001546 | Validation Time: 10.837804814014817
Epoch: 20/20
 Train Loss: 0.11442299939247513 | Validation Loss: 0.11405261328109538
Train Time: 42.95685380202485 | Validation Time: 10.799263519002125
torch.Size([320, 320])
torch.Size([320, 320])
torch.Size([320, 320])
Average SSIM: 0.38437191373748253
30
61
94
127
155
184
209
239
267
295
320
352
377
407
444
479
514
547
579
604
637
667
700
729
759
791
822
857
892
920
