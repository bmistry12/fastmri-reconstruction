epochs = 30
dropout_prob = 0.01
learning_rate = 0.1
weight_decay = 0.0
step_size = 15
lr_gamma = 0.1
num_pool_layers = 4

8
1 - RMSprop 
    train loss 0.07846426117761444
    val loss 0.08150636685173608
    ssim 0.38945210043609657

2 - Adam
    train loss - 0.07503074480556993
    val loss - 0.07745234528338588
    ssim - 0.3763127858946448

3 - Adagrad
    train loss - 0.07358963457107923
    test loss - 0.07458532385972155
    ssim - 0.32659110979079137	

4 - ASGD (Averaged Stochastic Gradient Descent)
    train loss -  0.07384624573476527
    validation loss - 0.07428537162101269
    ssim - 0.375864824351058

5 - SGD (Stochastic Gradient Descent)
    train loss - 0.07630648326060156
    validation loss - 0.07177936616278517
    ssim - 0.38620382100528033

4
1 - RMSprop
    train loss - 0.06703608721678002
    val loss - 0.06492528858087
    ssim - 0.42793198023964807
